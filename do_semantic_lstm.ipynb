{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# basics\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "# use only for tokenizer and padding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1019):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# SEED = 1019\n",
    "# seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "class Config:\n",
    "    num_epochs = 15\n",
    "    batch_size = 512\n",
    "    test_batch_size = 512\n",
    "    vocab_size = 120000\n",
    "    max_length = 72\n",
    "    embedding_size = 300\n",
    "    hidden_size = 64\n",
    "    num_layers = 1\n",
    "    embedding_dropout = 0.3\n",
    "    layer_dropout = 0.1\n",
    "    dense_size = [hidden_size*2*4, int(hidden_size/4)] # depend on concat num\n",
    "    output_size = 1\n",
    "    num_cv_splits = 5\n",
    "    learning_rate = 0.001\n",
    "    clip_grad = 5.0\n",
    "    embeddings = ['glove', 'paragram', 'fasttext']\n",
    "    datadir = Path('./data/')\n",
    "    # datadir = Path('../input') # for kernel\n",
    "\n",
    "c = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [\n",
    "    ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "    '/', '[', ']', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£',\n",
    "    '·', '_', '{', '}', '©', '^', '®', '`', '→', '°', '€', '™', '›',\n",
    "    '♥', '←', '×', '§', '″', '′', 'Â', '█', 'à', '…', '“', '★', '”',\n",
    "    '–', '●', 'â', '►', '−', '¢', '¬', '░', '¶', '↑', '±',  '▾',\n",
    "    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '⊕', '▼',\n",
    "    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "    'è', '¸', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "    '¹', '≤', '‡', '₹', '´'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"this's\": \"this is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"'re\": \" are\",\n",
    "    \"tryin'\": \"trying\",\n",
    "    \"doesn'\": \"does not\",\n",
    "    'howdo': 'how do',\n",
    "    'whatare': 'what are',\n",
    "    'howcan': 'how can',\n",
    "    'howmuch': 'how much',\n",
    "    'howmany': 'how many',\n",
    "    'whydo': 'why do',\n",
    "    'doI': 'do I',\n",
    "    'theBest': 'the best',\n",
    "    'howdoes': 'how does',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spells = {\n",
    "    'colour': 'color',\n",
    "    'centre': 'center',\n",
    "    'favourite': 'favorite',\n",
    "    'travelling': 'traveling',\n",
    "    'counselling': 'counseling',\n",
    "    'theatre': 'theater',\n",
    "    'cancelled': 'canceled',\n",
    "    'labour': 'labor',\n",
    "    'organisation': 'organization',\n",
    "    'wwii': 'world war 2',\n",
    "    'citicise': 'criticize',\n",
    "    'youtu.be': 'youtube',\n",
    "    'youtu ': 'youtube ',\n",
    "    'qoura': 'quora',\n",
    "    'sallary': 'salary',\n",
    "    'Whta': 'what',\n",
    "    'whta': 'what',\n",
    "    'narcisist': 'narcissist',\n",
    "    'mastrubation': 'masturbation',\n",
    "    'mastrubate': 'masturbate',\n",
    "    \"mastrubating\": 'masturbating',\n",
    "    'pennis': 'penis',\n",
    "    'Etherium': 'ethereum',\n",
    "    'etherium': 'ethereum',\n",
    "    'narcissit': 'narcissist',\n",
    "    'bigdata': 'big data',\n",
    "    '2k17': '2017',\n",
    "    '2k18': '2018',\n",
    "    'qouta': 'quota',\n",
    "    'exboyfriend': 'ex boyfriend',\n",
    "    'exgirlfriend': 'ex girlfriend',\n",
    "    'airhostess': 'air hostess',\n",
    "    \"whst\": 'what',\n",
    "    'watsapp': 'whatsapp',\n",
    "    'demonitisation': 'demonetization',\n",
    "    'demonitization': 'demonetization',\n",
    "    'demonetisation': 'demonetization',\n",
    "    'quorans': 'quora user',\n",
    "    'quoran': 'quora user',\n",
    "    'pokémon': 'pokemon',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datadir):\n",
    "    train_df = pd.read_csv(datadir / 'train_local.csv')\n",
    "    test_df = pd.read_csv(datadir / 'test_local.csv')\n",
    "    print(\"Train shape : \", train_df.shape)\n",
    "    print(\"Test shape : \", test_df.shape)\n",
    "    return train_df, test_df\n",
    "\n",
    "def clean(df):\n",
    "    df = clean_lower(df)\n",
    "    df = clean_unicode(df)\n",
    "    df = clean_abbreviation(df, abbreviations)\n",
    "    df = clean_spells(df, spells)\n",
    "    df = clean_language(df)\n",
    "    df = clean_puncts(df, puncts)\n",
    "    df = clean_space(df)\n",
    "    return df\n",
    "\n",
    "def clean_unicode(df):\n",
    "    codes = ['\\x7f', '\\u200b', '\\xa0', '\\ufeff', '\\u200e', '\\u202a', '\\u202c', '\\u2060', '\\uf0d8', '\\ue019', '\\uf02d', '\\u200f', '\\u2061', '\\ue01b']\n",
    "    df[\"question_text\"] = df[\"question_text\"].apply(lambda x: _clean_unicode(x, codes))\n",
    "    return df\n",
    "\n",
    "def _clean_unicode(x, codes):\n",
    "    for u in codes:\n",
    "        if u in x:\n",
    "            x = x.replace(u, '')\n",
    "    return x\n",
    "\n",
    "def clean_language(df):\n",
    "    langs1 = r'[\\p{Katakana}\\p{Hiragana}\\p{Han}]' # regex\n",
    "    langs2 = r'[ஆய்தஎழுத்துஆயுதஎழுத்துशुषछछशुषدوउसशुष북한내제តើបងប្អូនមានមធ្យបាយអ្វីខ្លះដើម្បីរកឃើញឯកសារអំពីប្រវត្តិស្ត្រនៃប្រាសាទអង្គរវट्टरौरआदસંઘરાજ્યपीतऊनअहএকটিবাড়িএকটিখামারএরঅধীনেপদেরবাছাইপরীক্ষাএরপ্রশ্নওউত্তরসহকোথায়পেতেপারিص、。Емелядуракلكلمقاممقال수능ί서로가를행복하게기乡국고등학교는몇시간업니《》싱관없어나이रचा키کپڤ」मिलगईकलेजेकोठंडकऋॠऌॡर]'\n",
    "    compiled_langs1 = regex.compile(langs1)\n",
    "    compiled_langs2 = re.compile(langs2)\n",
    "    df['question_text'] = df['question_text'].apply(lambda x: _clean_language(x, compiled_langs1))\n",
    "    df['question_text'] = df['question_text'].apply(lambda x: _clean_language(x, compiled_langs2))\n",
    "    return df\n",
    "\n",
    "def _clean_language(x, compiled_re):\n",
    "    return compiled_re.sub(' <lang> ', x)\n",
    "\n",
    "def clean_lower(df):\n",
    "    df[\"question_text\"] = df[\"question_text\"].apply(lambda x: x.lower())\n",
    "    return df\n",
    "\n",
    "def clean_puncts(df, puncts):\n",
    "    df['question_text'] = df['question_text'].apply(lambda x: _clean_puncts(x, puncts))\n",
    "    return df\n",
    "    \n",
    "def _clean_puncts(x, puncts):\n",
    "    x = str(x)\n",
    "    # added space around puncts after replace\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "def clean_spells(df, spells):\n",
    "    compiled_spells = re.compile('(%s)' % '|'.join(spells.keys()))\n",
    "    def replace(match):\n",
    "        return spells[match.group(0)]\n",
    "    df['question_text'] = df[\"question_text\"].apply(\n",
    "        lambda x: _clean_spells(x, compiled_spells, replace)\n",
    "    )\n",
    "    return df\n",
    "    \n",
    "def _clean_spells(x, compiled_re, replace):\n",
    "    return compiled_re.sub(replace, x)\n",
    "\n",
    "def clean_abbreviation(df, abbreviations):\n",
    "    compiled_abbreviation = re.compile('(%s)' % '|'.join(abbreviations.keys()))\n",
    "    def replace(match):\n",
    "        return abbreviations[match.group(0)]\n",
    "    df['question_text'] = df[\"question_text\"].apply(\n",
    "        lambda x: _clean_abreviation(x, compiled_abbreviation, replace)\n",
    "    )\n",
    "    return df\n",
    "    \n",
    "def _clean_abreviation(x, compiled_re, replace):\n",
    "    return compiled_re.sub(replace, x)\n",
    "\n",
    "def clean_space(df):\n",
    "    compiled_re = re.compile(r\"\\s+\")\n",
    "    df['question_text'] = df[\"question_text\"].apply(lambda x: _clean_space(x, compiled_re))\n",
    "    return df\n",
    "\n",
    "def _clean_space(x, compiled_re):\n",
    "    return compiled_re.sub(\" \", x)\n",
    "        \n",
    "def prepare_tokenizer(texts, max_words):\n",
    "    tokenizer = Tokenizer(num_words=max_words, filters='', oov_token='<unk>')\n",
    "    tokenizer.fit_on_texts(list(texts))\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize_and_padding(texts, tokenizer, max_length):\n",
    "    texts = tokenizer.texts_to_sequences(texts)\n",
    "    texts = pad_sequences(texts, maxlen=max_length)\n",
    "    return texts\n",
    "\n",
    "def get_all_vocabs(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: Config, tokenizer, all_vocabs, embedding_weights = None):\n",
    "        super(Embeddings, self).__init__()\n",
    "        \n",
    "        self.embedding_map = {\n",
    "            'fasttext': self._load_fasttext,\n",
    "            'glove': self._load_glove,\n",
    "            'paragram': self._load_paragram\n",
    "        }\n",
    "        self.c = config\n",
    "        self.tokenizer = tokenizer\n",
    "        self.all_vocabs = all_vocabs\n",
    "        \n",
    "        if embedding_weights is None:\n",
    "            embedding_weights = self._load_embeddings(self.c.embeddings)\n",
    "            \n",
    "        self.original_embedding_weights = embedding_weights\n",
    "        self.embeddings = nn.Embedding(self.c.vocab_size + 1, self.c.embedding_size, padding_idx=0)\n",
    "        self.embeddings.weight = nn.Parameter(embedding_weights)\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.embedding_dropout = nn.Dropout2d(self.c.embedding_dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.embeddings(x)\n",
    "        return self.embedding_dropout(embedding.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "    \n",
    "    def reset_weights(self):\n",
    "        self.embeddings.weight = nn.Parameter(self.original_embedding_weights)\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "    \n",
    "    def _load_embeddings(self, embedding_list: list):\n",
    "        embedding_weights = np.zeros((self.c.vocab_size, self.c.embedding_size))\n",
    "        pool = Pool(num_cores)\n",
    "        embedding_weights = np.mean(pool.map(self._load_an_embedding, embedding_list), 0)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return torch.tensor(embedding_weights, dtype=torch.float32)\n",
    "\n",
    "    def _load_an_embedding(self, emb):\n",
    "        return self.embedding_map[emb](self.tokenizer.word_index)\n",
    "        \n",
    "    def _get_embeddings_pair(self, word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "        \n",
    "    def _make_embeddings(self, embeddings_index, word_index, emb_mean, emb_std):\n",
    "        nb_words = min(self.c.vocab_size, len(word_index))\n",
    "        embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, self.c.embedding_size))\n",
    "        embedding_matrix[0] = np.zeros(self.c.embedding_size)\n",
    "        for word, i in word_index.items():\n",
    "            if i >= self.c.vocab_size:\n",
    "                continue\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "\n",
    "        return embedding_matrix\n",
    "    \n",
    "    def _load_glove(self, word_index):\n",
    "        print('loading glove')\n",
    "        filepath = self.c.datadir / 'embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "        embeddings_index = dict(\n",
    "            self._get_embeddings_pair(*o.split(\" \"))\n",
    "            for o in open(filepath)\n",
    "            if o.split(\" \")[0] in word_index\n",
    "        )\n",
    "        emb_mean, emb_std = -0.005838499, 0.48782197\n",
    "        return self._make_embeddings(embeddings_index, word_index, emb_mean, emb_std)\n",
    "    \n",
    "    def _load_fasttext(self, word_index):    \n",
    "        print('loading fasttext')\n",
    "        filepath = self.c.datadir / 'embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "        embeddings_index = dict(\n",
    "            self._get_embeddings_pair(*o.split(\" \"))\n",
    "            for o in open(filepath)\n",
    "            if len(o) > 100 and o.split(\" \")[0] in word_index\n",
    "        )\n",
    "        emb_mean, emb_std = -0.0033469985, 0.109855495\n",
    "        return self._make_embeddings(embeddings_index, word_index, emb_mean, emb_std)\n",
    "\n",
    "    def _load_paragram(self, word_index):\n",
    "        print('loading paragram')\n",
    "        filepath = self.c.datadir / 'embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "        embeddings_index = dict(\n",
    "            self._get_embeddings_pair(*o.split(\" \"))\n",
    "            for o in open(filepath, encoding=\"utf8\", errors='ignore')\n",
    "            if len(o) > 100 and o.split(\" \")[0] in word_index\n",
    "        )\n",
    "        emb_mean, emb_std = -0.0053247833, 0.49346462\n",
    "        return self._make_embeddings(embeddings_index, word_index, emb_mean, emb_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 2\n",
    "def df_parallelize_run(df, func, num_cores=2):\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1175509, 3)\n",
      "Test shape :  (130613, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_data(c.datadir)\n",
    "train_df = df_parallelize_run(train_df, clean)\n",
    "test_df = df_parallelize_run(test_df, clean)\n",
    "train_x, train_y = train_df['question_text'].values, train_df['target'].values\n",
    "test_x = test_df['question_text'].values\n",
    "tokenizer = prepare_tokenizer(train_x, c.vocab_size)\n",
    "train_x = tokenize_and_padding(train_x, tokenizer, c.max_length)\n",
    "test_x = tokenize_and_padding(test_x, tokenizer, c.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_vocabs:  184279\n",
      "loading glove\n",
      "loading paragram\n",
      "loading fasttext\n",
      "49.51735496520996\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_vocabs = get_all_vocabs(train_df['question_text'])\n",
    "print('all_vocabs: ', len(all_vocabs))\n",
    "embeddings = Embeddings(c, tokenizer, all_vocabs)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRULayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(GRULayer, self).__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          bias=False,\n",
    "                          bidirectional=True,\n",
    "                          batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n",
    "        for k in ih:\n",
    "            nn.init.xavier_uniform_(k)\n",
    "        for k in hh:\n",
    "            nn.init.orthogonal_(k)\n",
    "        for k in b:\n",
    "            nn.init.constant_(k, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_outputs, gru_state = self.gru(x)\n",
    "        return self.dropout(gru_outputs), gru_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(LSTMLayer, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            bias=False,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n",
    "        for k in ih:\n",
    "            nn.init.xavier_uniform_(k)\n",
    "        for k in hh:\n",
    "            nn.init.orthogonal_(k)\n",
    "        for k in b:\n",
    "            nn.init.constant_(k, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_outputs, (lstm_states, _) = self.lstm(x)\n",
    "        return self.dropout(lstm_outputs), lstm_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, config: Config, embeddings):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.c = config\n",
    "        \n",
    "        self.embedding = embeddings\n",
    "        self.lstm1 = LSTMLayer(input_size=self.c.embedding_size,\n",
    "                              hidden_size=self.c.hidden_size,\n",
    "                              num_layers=self.c.num_layers,\n",
    "                              dropout_rate=self.c.layer_dropout)\n",
    "        self.lstm2 = LSTMLayer(input_size=self.c.hidden_size*2,\n",
    "                            hidden_size=self.c.hidden_size,\n",
    "                            num_layers=self.c.num_layers,\n",
    "                            dropout_rate=self.c.layer_dropout)\n",
    "        \n",
    "        self.cell_dropout = nn.Dropout(self.c.layer_dropout)\n",
    "        self.linear = nn.Linear(self.c.dense_size[0], self.c.dense_size[1])\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(self.c.dense_size[1])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(self.c.layer_dropout)\n",
    "        self.out = nn.Linear(self.c.dense_size[1], self.c.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        o_lstm1, h_lstm1 = self.lstm1(h_embedding)\n",
    "        o_lstm2, h_lstm2 = self.lstm2(o_lstm1)\n",
    "        \n",
    "        avg_pool = torch.mean(o_lstm2, 1)\n",
    "        max_pool, _ = torch.max(o_lstm2, 1)\n",
    "        \n",
    "        h_lstm1 = self.cell_dropout(torch.cat(h_lstm1.split(1, 0), -1).squeeze(0))\n",
    "        h_lstm2 = self.cell_dropout(torch.cat(h_lstm2.split(1, 0), -1).squeeze(0))\n",
    "\n",
    "        concat = torch.cat([h_lstm1, h_lstm2, avg_pool, max_pool], 1)\n",
    "        concat = self.linear(concat)\n",
    "        concat = self.batch_norm(concat)\n",
    "        concat = self.relu(concat)\n",
    "        concat = self.dropout(concat)\n",
    "        out = self.out(concat)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def threshold_search(y_true, y_proba, plot=False):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    thresholds = np.append(thresholds, 1.001) \n",
    "    F = 2 / (1/precision + 1/recall)\n",
    "    best_score = np.max(F)\n",
    "    best_th = thresholds[np.argmax(F)]\n",
    "    if plot:\n",
    "        plt.plot(thresholds, F, '-b')\n",
    "        plt.plot([best_th], [best_score], '*r')\n",
    "        plt.show()\n",
    "    search_result = {'threshold': best_th , 'f1': best_score}\n",
    "    return search_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_length(data, mask):\n",
    "    max_length = data.shape[1]\n",
    "    transposed = torch.transpose(data, 1, 0)\n",
    "    res = (transposed == mask).all(1)\n",
    "    for i, r in enumerate(res):\n",
    "        if r == 0:\n",
    "            break\n",
    "    data = data[:, -(max_length - i):]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_x, train_y, test_x, c, embeddings, trial=0):\n",
    "    splits = list(StratifiedKFold(n_splits=c.num_cv_splits, shuffle=True).split(train_x, train_y))\n",
    "    x_test_cuda = torch.tensor(test_x, dtype=torch.long).cuda(cuda_idx)\n",
    "    test = torch.utils.data.TensorDataset(x_test_cuda)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=c.test_batch_size, shuffle=False)\n",
    "    train_preds = np.zeros((len(train_x)))\n",
    "    test_preds = np.zeros((len(test_x)))\n",
    "\n",
    "    mask = torch.zeros((c.max_length, 1), dtype=torch.long).cuda(cuda_idx)\n",
    "    \n",
    "    for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "        x_train_fold = torch.tensor(train_x[train_idx], dtype=torch.long).cuda(cuda_idx)\n",
    "        y_train_fold = torch.tensor(train_y[train_idx, np.newaxis], dtype=torch.float32).cuda(cuda_idx)\n",
    "        x_val_fold = torch.tensor(train_x[valid_idx], dtype=torch.long).cuda(cuda_idx)\n",
    "        y_val_fold = torch.tensor(train_y[valid_idx, np.newaxis], dtype=torch.float32).cuda(cuda_idx)\n",
    "\n",
    "        model = SimpleRNN(c, embeddings)\n",
    "        model.cuda(cuda_idx)\n",
    "\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=c.learning_rate)\n",
    "\n",
    "        train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "        valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=c.batch_size, shuffle=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=c.test_batch_size, shuffle=False)\n",
    "        \n",
    "        best_f1 = 0.0\n",
    "        best_epoch = 0\n",
    "\n",
    "        print(f'Fold {i + 1}')\n",
    "\n",
    "        for epoch in range(c.num_epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            model.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = cut_length(x_batch, mask)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), c.clip_grad)\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            valid_preds_fold = np.zeros((x_val_fold.size(0)))\n",
    "            avg_val_loss = 0.\n",
    "\n",
    "            # validation prediction\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "                x_batch = cut_length(x_batch, mask)\n",
    "                y_pred = model(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                valid_preds_fold[i * c.test_batch_size:(i+1) * c.test_batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "            search_result = threshold_search(y_val_fold.cpu().numpy(), valid_preds_fold)\n",
    "            valid_pred_targets = valid_preds_fold > search_result['threshold']\n",
    "            val_f1 = f1_score(y_val_fold.cpu().numpy(), valid_pred_targets)\n",
    "\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Epoch {}/{}  loss={:.4f}  val_loss={:.4f}  f1={:.3f}  time={:.2f}s'.format(\n",
    "                epoch + 1, c.num_epochs, avg_loss, avg_val_loss, val_f1, elapsed_time))\n",
    "            if best_f1 < val_f1:\n",
    "                print(f'model_saved at f1: {val_f1} from {best_f1}')\n",
    "                ckpt_path = Path(f'./ckpt/do_semantic/{trial}/')\n",
    "                if not ckpt_path.exists():\n",
    "                    ckpt_path.mkdir(parents=True)\n",
    "                torch.save(model.state_dict(), ckpt_path / f'{i}_model.pt')\n",
    "                best_f1 = val_f1\n",
    "                best_epoch = epoch\n",
    "\n",
    "        # test prediction\n",
    "        model.load_state_dict(torch.load(f'./ckpt/do_semantic/{trial}/{i}_model.pt'))  # load best model\n",
    "        test_preds_fold = np.zeros(len(test_x))\n",
    "        for i, (x_batch, ) in enumerate(test_loader):\n",
    "            x_batch = cut_length(x_batch, mask)\n",
    "            y_pred = model(x_batch).detach()\n",
    "            test_preds_fold[i * c.test_batch_size:(i+1) * c.test_batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "        train_preds[valid_idx] = valid_preds_fold\n",
    "        test_preds += test_preds_fold / len(splits)\n",
    "    return train_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15  loss=0.1620  val_loss=0.1090  f1=0.645  time=152.97s\n",
      "model_saved at f1: 0.6449445324881141 from 0.0\n",
      "Epoch 2/15  loss=0.1119  val_loss=0.1025  f1=0.666  time=157.02s\n",
      "model_saved at f1: 0.6659471127900701 from 0.6449445324881141\n",
      "Epoch 3/15  loss=0.1062  val_loss=0.1001  f1=0.673  time=158.84s\n",
      "model_saved at f1: 0.6728890002505638 from 0.6659471127900701\n",
      "Epoch 4/15  loss=0.1025  val_loss=0.0986  f1=0.682  time=154.31s\n",
      "model_saved at f1: 0.6822738149130182 from 0.6728890002505638\n",
      "Epoch 5/15  loss=0.0998  val_loss=0.0974  f1=0.684  time=154.99s\n",
      "model_saved at f1: 0.6844079183380621 from 0.6822738149130182\n",
      "Epoch 6/15  loss=0.0974  val_loss=0.0960  f1=0.688  time=153.20s\n",
      "model_saved at f1: 0.6876768716233599 from 0.6844079183380621\n",
      "Epoch 7/15  loss=0.0953  val_loss=0.0954  f1=0.689  time=162.24s\n",
      "model_saved at f1: 0.6893258989683149 from 0.6876768716233599\n",
      "Epoch 8/15  loss=0.0935  val_loss=0.0960  f1=0.691  time=154.61s\n",
      "model_saved at f1: 0.6913603940760643 from 0.6893258989683149\n",
      "Epoch 9/15  loss=0.0918  val_loss=0.0962  f1=0.690  time=154.71s\n",
      "Epoch 10/15  loss=0.0903  val_loss=0.0951  f1=0.692  time=154.55s\n",
      "model_saved at f1: 0.6919648624208757 from 0.6913603940760643\n",
      "Epoch 11/15  loss=0.0887  val_loss=0.0954  f1=0.694  time=155.46s\n",
      "model_saved at f1: 0.6938909281594127 from 0.6919648624208757\n",
      "Epoch 12/15  loss=0.0875  val_loss=0.0960  f1=0.692  time=160.75s\n",
      "Epoch 13/15  loss=0.0862  val_loss=0.0951  f1=0.697  time=154.02s\n",
      "model_saved at f1: 0.6966088532228838 from 0.6938909281594127\n",
      "Epoch 14/15  loss=0.0851  val_loss=0.0968  f1=0.694  time=154.24s\n",
      "Epoch 15/15  loss=0.0842  val_loss=0.0963  f1=0.693  time=153.13s\n",
      "Fold 2\n",
      "Epoch 1/15  loss=0.1492  val_loss=0.1085  f1=0.648  time=160.49s\n",
      "model_saved at f1: 0.6476952168387118 from 0.0\n",
      "Epoch 2/15  loss=0.1115  val_loss=0.1044  f1=0.664  time=157.19s\n",
      "model_saved at f1: 0.6642264977318942 from 0.6476952168387118\n",
      "Epoch 3/15  loss=0.1059  val_loss=0.0998  f1=0.675  time=155.95s\n",
      "model_saved at f1: 0.6752278635637549 from 0.6642264977318942\n",
      "Epoch 4/15  loss=0.1024  val_loss=0.0978  f1=0.680  time=150.77s\n",
      "model_saved at f1: 0.6803149606299213 from 0.6752278635637549\n",
      "Epoch 5/15  loss=0.0996  val_loss=0.0982  f1=0.685  time=154.21s\n",
      "model_saved at f1: 0.6847094997117417 from 0.6803149606299213\n",
      "Epoch 6/15  loss=0.0970  val_loss=0.0965  f1=0.688  time=162.25s\n",
      "model_saved at f1: 0.6880800785580792 from 0.6847094997117417\n",
      "Epoch 7/15  loss=0.0950  val_loss=0.0954  f1=0.689  time=153.89s\n",
      "model_saved at f1: 0.6890497168030209 from 0.6880800785580792\n",
      "Epoch 8/15  loss=0.0930  val_loss=0.0976  f1=0.692  time=154.82s\n",
      "model_saved at f1: 0.6921265355483419 from 0.6890497168030209\n",
      "Epoch 9/15  loss=0.0916  val_loss=0.0962  f1=0.690  time=155.19s\n",
      "Epoch 10/15  loss=0.0898  val_loss=0.0950  f1=0.692  time=161.38s\n",
      "Epoch 11/15  loss=0.0884  val_loss=0.0961  f1=0.691  time=156.43s\n",
      "Epoch 12/15  loss=0.0869  val_loss=0.0953  f1=0.691  time=154.15s\n",
      "Epoch 13/15  loss=0.0860  val_loss=0.0971  f1=0.692  time=154.76s\n",
      "Epoch 14/15  loss=0.0847  val_loss=0.0963  f1=0.690  time=154.12s\n",
      "Epoch 15/15  loss=0.0835  val_loss=0.0972  f1=0.692  time=163.18s\n",
      "Fold 3\n",
      "Epoch 1/15  loss=0.1527  val_loss=0.1104  f1=0.647  time=154.14s\n",
      "model_saved at f1: 0.6472218641227279 from 0.0\n",
      "Epoch 2/15  loss=0.1113  val_loss=0.1033  f1=0.667  time=155.50s\n",
      "model_saved at f1: 0.6674295159085852 from 0.6472218641227279\n",
      "Epoch 3/15  loss=0.1059  val_loss=0.1011  f1=0.676  time=155.24s\n",
      "model_saved at f1: 0.6757580421733107 from 0.6674295159085852\n",
      "Epoch 4/15  loss=0.1023  val_loss=0.0995  f1=0.680  time=154.81s\n",
      "model_saved at f1: 0.6796392077709096 from 0.6757580421733107\n",
      "Epoch 5/15  loss=0.0994  val_loss=0.0991  f1=0.686  time=162.80s\n",
      "model_saved at f1: 0.6857325451350056 from 0.6796392077709096\n",
      "Epoch 6/15  loss=0.0970  val_loss=0.0982  f1=0.684  time=155.60s\n",
      "Epoch 7/15  loss=0.0947  val_loss=0.0971  f1=0.687  time=155.70s\n",
      "model_saved at f1: 0.6874571847985648 from 0.6857325451350056\n",
      "Epoch 8/15  loss=0.0929  val_loss=0.0968  f1=0.687  time=150.61s\n",
      "Epoch 9/15  loss=0.0912  val_loss=0.0980  f1=0.690  time=162.77s\n",
      "model_saved at f1: 0.69002574002574 from 0.6874571847985648\n",
      "Epoch 10/15  loss=0.0898  val_loss=0.0971  f1=0.688  time=155.40s\n",
      "Epoch 11/15  loss=0.0883  val_loss=0.0972  f1=0.690  time=155.21s\n",
      "model_saved at f1: 0.6904064733478166 from 0.69002574002574\n",
      "Epoch 12/15  loss=0.0870  val_loss=0.0972  f1=0.690  time=153.23s\n",
      "Epoch 13/15  loss=0.0855  val_loss=0.0983  f1=0.691  time=154.86s\n",
      "model_saved at f1: 0.6905573408640893 from 0.6904064733478166\n",
      "Epoch 14/15  loss=0.0846  val_loss=0.1003  f1=0.689  time=161.48s\n",
      "Epoch 15/15  loss=0.0834  val_loss=0.0990  f1=0.688  time=154.88s\n",
      "Fold 4\n",
      "Epoch 1/15  loss=0.1821  val_loss=0.1120  f1=0.643  time=155.30s\n",
      "model_saved at f1: 0.6426725252003102 from 0.0\n",
      "Epoch 2/15  loss=0.1124  val_loss=0.1046  f1=0.665  time=156.34s\n",
      "model_saved at f1: 0.6649187875687428 from 0.6426725252003102\n",
      "Epoch 3/15  loss=0.1064  val_loss=0.1018  f1=0.673  time=155.97s\n",
      "model_saved at f1: 0.6728305375775987 from 0.6649187875687428\n",
      "Epoch 4/15  loss=0.1025  val_loss=0.1026  f1=0.678  time=161.25s\n",
      "model_saved at f1: 0.6776950114475508 from 0.6728305375775987\n",
      "Epoch 5/15  loss=0.0998  val_loss=0.0994  f1=0.681  time=156.34s\n",
      "model_saved at f1: 0.6814613819168523 from 0.6776950114475508\n",
      "Epoch 6/15  loss=0.0973  val_loss=0.0981  f1=0.685  time=154.58s\n",
      "model_saved at f1: 0.6851065209637148 from 0.6814613819168523\n",
      "Epoch 7/15  loss=0.0953  val_loss=0.0991  f1=0.684  time=155.11s\n",
      "Epoch 8/15  loss=0.0936  val_loss=0.0975  f1=0.688  time=162.90s\n",
      "model_saved at f1: 0.6879594093540623 from 0.6851065209637148\n",
      "Epoch 9/15  loss=0.0916  val_loss=0.0975  f1=0.686  time=156.28s\n",
      "Epoch 10/15  loss=0.0899  val_loss=0.0980  f1=0.688  time=155.67s\n",
      "Epoch 11/15  loss=0.0886  val_loss=0.0977  f1=0.689  time=155.01s\n",
      "model_saved at f1: 0.688923006565838 from 0.6879594093540623\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0982  f1=0.691  time=149.36s\n",
      "model_saved at f1: 0.6907052839602165 from 0.688923006565838\n",
      "Epoch 13/15  loss=0.0856  val_loss=0.1021  f1=0.688  time=163.09s\n",
      "Epoch 14/15  loss=0.0847  val_loss=0.0988  f1=0.688  time=155.94s\n",
      "Epoch 15/15  loss=0.0838  val_loss=0.0989  f1=0.690  time=155.83s\n",
      "Fold 5\n",
      "Epoch 1/15  loss=0.1900  val_loss=0.1110  f1=0.637  time=156.77s\n",
      "model_saved at f1: 0.6366575956459101 from 0.0\n",
      "Epoch 2/15  loss=0.1128  val_loss=0.1052  f1=0.657  time=156.37s\n",
      "model_saved at f1: 0.6566742626055141 from 0.6366575956459101\n",
      "Epoch 3/15  loss=0.1069  val_loss=0.1028  f1=0.666  time=161.54s\n",
      "model_saved at f1: 0.6664298171952717 from 0.6566742626055141\n",
      "Epoch 4/15  loss=0.1034  val_loss=0.1003  f1=0.674  time=155.61s\n",
      "model_saved at f1: 0.6736280537393059 from 0.6664298171952717\n",
      "Epoch 5/15  loss=0.1000  val_loss=0.0997  f1=0.678  time=154.72s\n",
      "model_saved at f1: 0.6779108768567321 from 0.6736280537393059\n",
      "Epoch 6/15  loss=0.0978  val_loss=0.0992  f1=0.681  time=155.41s\n",
      "model_saved at f1: 0.6807386202774545 from 0.6779108768567321\n",
      "Epoch 7/15  loss=0.0956  val_loss=0.0986  f1=0.683  time=162.17s\n",
      "model_saved at f1: 0.6830346980585998 from 0.6807386202774545\n",
      "Epoch 8/15  loss=0.0935  val_loss=0.0973  f1=0.683  time=155.90s\n",
      "Epoch 9/15  loss=0.0918  val_loss=0.0972  f1=0.685  time=156.24s\n",
      "model_saved at f1: 0.6846124715980813 from 0.6830346980585998\n",
      "Epoch 10/15  loss=0.0900  val_loss=0.1001  f1=0.686  time=155.62s\n",
      "model_saved at f1: 0.6861404194346751 from 0.6846124715980813\n",
      "Epoch 11/15  loss=0.0886  val_loss=0.0993  f1=0.684  time=153.33s\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0992  f1=0.684  time=163.13s\n",
      "Epoch 13/15  loss=0.0860  val_loss=0.0986  f1=0.686  time=154.54s\n",
      "model_saved at f1: 0.6861786512124841 from 0.6861404194346751\n",
      "Epoch 14/15  loss=0.0849  val_loss=0.1007  f1=0.686  time=154.82s\n",
      "Epoch 15/15  loss=0.0838  val_loss=0.0996  f1=0.687  time=155.13s\n",
      "model_saved at f1: 0.6871344084284006 from 0.6861786512124841\n",
      "{'threshold': 0.3180008828639984, 'f1': 0.6896214770623329}\n",
      "f1 score: 0.7003850192509626\n"
     ]
    }
   ],
   "source": [
    "train_preds, test_preds = training(train_x, train_y, test_x, c, embeddings)\n",
    "search_result = threshold_search(train_y, train_preds)\n",
    "print(search_result)\n",
    "test_pred_targets = test_preds > search_result['threshold']\n",
    "f1 = f1_score(test_df['target'], test_pred_targets)\n",
    "print('f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15  loss=0.1571  val_loss=0.1099  f1=0.648  time=156.72s\n",
      "model_saved at f1: 0.6481239022832508 from 0.0\n",
      "Epoch 2/15  loss=0.1118  val_loss=0.1038  f1=0.662  time=158.41s\n",
      "model_saved at f1: 0.662444585180494 from 0.6481239022832508\n",
      "Epoch 3/15  loss=0.1064  val_loss=0.1006  f1=0.672  time=153.84s\n",
      "model_saved at f1: 0.6719191123366818 from 0.662444585180494\n",
      "Epoch 4/15  loss=0.1026  val_loss=0.0991  f1=0.679  time=154.91s\n",
      "model_saved at f1: 0.6791777792233137 from 0.6719191123366818\n",
      "Epoch 5/15  loss=0.0998  val_loss=0.0978  f1=0.682  time=153.47s\n",
      "model_saved at f1: 0.6822134896605038 from 0.6791777792233137\n",
      "Epoch 6/15  loss=0.0972  val_loss=0.0968  f1=0.686  time=162.70s\n",
      "model_saved at f1: 0.6863890053876182 from 0.6822134896605038\n",
      "Epoch 7/15  loss=0.0952  val_loss=0.0963  f1=0.689  time=153.70s\n",
      "model_saved at f1: 0.6885781034979358 from 0.6863890053876182\n",
      "Epoch 8/15  loss=0.0933  val_loss=0.0962  f1=0.689  time=155.09s\n",
      "model_saved at f1: 0.6886764753857697 from 0.6885781034979358\n",
      "Epoch 9/15  loss=0.0917  val_loss=0.0972  f1=0.689  time=154.50s\n",
      "model_saved at f1: 0.6892432851239669 from 0.6886764753857697\n",
      "Epoch 10/15  loss=0.0901  val_loss=0.0963  f1=0.688  time=159.06s\n",
      "Epoch 11/15  loss=0.0888  val_loss=0.0974  f1=0.689  time=157.78s\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0966  f1=0.689  time=154.21s\n",
      "model_saved at f1: 0.6893439777854913 from 0.6892432851239669\n",
      "Epoch 13/15  loss=0.0861  val_loss=0.0988  f1=0.687  time=154.46s\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0960  f1=0.691  time=154.33s\n",
      "model_saved at f1: 0.6907087402955171 from 0.6893439777854913\n",
      "Epoch 15/15  loss=0.0841  val_loss=0.0975  f1=0.691  time=163.20s\n",
      "model_saved at f1: 0.6908780039894881 from 0.6907087402955171\n",
      "Fold 2\n",
      "Epoch 1/15  loss=0.1529  val_loss=0.1129  f1=0.635  time=154.49s\n",
      "model_saved at f1: 0.6350371894287069 from 0.0\n",
      "Epoch 2/15  loss=0.1117  val_loss=0.1032  f1=0.667  time=154.14s\n",
      "model_saved at f1: 0.6674818986323411 from 0.6350371894287069\n",
      "Epoch 3/15  loss=0.1062  val_loss=0.1003  f1=0.673  time=154.12s\n",
      "model_saved at f1: 0.6726474640351159 from 0.6674818986323411\n",
      "Epoch 4/15  loss=0.1027  val_loss=0.0981  f1=0.680  time=154.64s\n",
      "model_saved at f1: 0.6802681621865533 from 0.6726474640351159\n",
      "Epoch 5/15  loss=0.0999  val_loss=0.0970  f1=0.686  time=163.74s\n",
      "model_saved at f1: 0.6855435770879335 from 0.6802681621865533\n",
      "Epoch 6/15  loss=0.0978  val_loss=0.0968  f1=0.691  time=150.27s\n",
      "model_saved at f1: 0.6908560311284047 from 0.6855435770879335\n",
      "Epoch 7/15  loss=0.0957  val_loss=0.0968  f1=0.689  time=154.13s\n",
      "Epoch 8/15  loss=0.0939  val_loss=0.0966  f1=0.692  time=154.08s\n",
      "model_saved at f1: 0.6924876691539144 from 0.6908560311284047\n",
      "Epoch 9/15  loss=0.0919  val_loss=0.0951  f1=0.693  time=163.11s\n",
      "model_saved at f1: 0.6931275029066013 from 0.6924876691539144\n",
      "Epoch 10/15  loss=0.0905  val_loss=0.0958  f1=0.693  time=154.37s\n",
      "Epoch 11/15  loss=0.0890  val_loss=0.0955  f1=0.695  time=155.01s\n",
      "model_saved at f1: 0.6947462610251822 from 0.6931275029066013\n",
      "Epoch 12/15  loss=0.0874  val_loss=0.0960  f1=0.696  time=154.88s\n",
      "model_saved at f1: 0.696404308202154 from 0.6947462610251822\n",
      "Epoch 13/15  loss=0.0860  val_loss=0.0963  f1=0.695  time=154.07s\n",
      "Epoch 14/15  loss=0.0848  val_loss=0.0974  f1=0.695  time=160.36s\n",
      "Epoch 15/15  loss=0.0837  val_loss=0.0977  f1=0.697  time=155.58s\n",
      "model_saved at f1: 0.69700800674252 from 0.696404308202154\n",
      "Fold 3\n",
      "Epoch 1/15  loss=0.1595  val_loss=0.1124  f1=0.643  time=154.88s\n",
      "model_saved at f1: 0.6426827283086439 from 0.0\n",
      "Epoch 2/15  loss=0.1124  val_loss=0.1057  f1=0.662  time=155.72s\n",
      "model_saved at f1: 0.6620325228823954 from 0.6426827283086439\n",
      "Epoch 3/15  loss=0.1066  val_loss=0.1020  f1=0.672  time=158.23s\n",
      "model_saved at f1: 0.6718571971135586 from 0.6620325228823954\n",
      "Epoch 4/15  loss=0.1032  val_loss=0.1006  f1=0.676  time=158.53s\n",
      "model_saved at f1: 0.6756514501568602 from 0.6718571971135586\n",
      "Epoch 5/15  loss=0.1001  val_loss=0.0992  f1=0.682  time=156.49s\n",
      "model_saved at f1: 0.6820072802912117 from 0.6756514501568602\n",
      "Epoch 6/15  loss=0.0975  val_loss=0.0979  f1=0.687  time=154.95s\n",
      "model_saved at f1: 0.6866334244812611 from 0.6820072802912117\n",
      "Epoch 7/15  loss=0.0954  val_loss=0.0973  f1=0.687  time=155.75s\n",
      "model_saved at f1: 0.6868088592041838 from 0.6866334244812611\n",
      "Epoch 8/15  loss=0.0933  val_loss=0.0966  f1=0.690  time=163.04s\n",
      "model_saved at f1: 0.6902711323763955 from 0.6868088592041838\n",
      "Epoch 9/15  loss=0.0916  val_loss=0.0983  f1=0.688  time=155.21s\n",
      "Epoch 10/15  loss=0.0899  val_loss=0.0978  f1=0.691  time=151.04s\n",
      "model_saved at f1: 0.6913734243697479 from 0.6902711323763955\n",
      "Epoch 11/15  loss=0.0886  val_loss=0.0987  f1=0.691  time=156.96s\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0966  f1=0.692  time=159.73s\n",
      "model_saved at f1: 0.6918243132094095 from 0.6913734243697479\n",
      "Epoch 13/15  loss=0.0856  val_loss=0.0990  f1=0.690  time=158.72s\n",
      "Epoch 14/15  loss=0.0848  val_loss=0.0982  f1=0.691  time=155.43s\n",
      "Epoch 15/15  loss=0.0834  val_loss=0.0992  f1=0.689  time=156.12s\n",
      "Fold 4\n",
      "Epoch 1/15  loss=0.1506  val_loss=0.1152  f1=0.642  time=155.03s\n",
      "model_saved at f1: 0.6417725441586613 from 0.0\n",
      "Epoch 2/15  loss=0.1114  val_loss=0.1034  f1=0.665  time=161.01s\n",
      "model_saved at f1: 0.6650637476668038 from 0.6417725441586613\n",
      "Epoch 3/15  loss=0.1058  val_loss=0.1001  f1=0.676  time=155.95s\n",
      "model_saved at f1: 0.6761529008472932 from 0.6650637476668038\n",
      "Epoch 4/15  loss=0.1022  val_loss=0.0998  f1=0.680  time=156.22s\n",
      "model_saved at f1: 0.6798388643775177 from 0.6761529008472932\n",
      "Epoch 5/15  loss=0.0997  val_loss=0.0978  f1=0.682  time=154.51s\n",
      "model_saved at f1: 0.682420637486261 from 0.6798388643775177\n",
      "Epoch 6/15  loss=0.0972  val_loss=0.0969  f1=0.685  time=153.58s\n",
      "model_saved at f1: 0.6851287209631284 from 0.682420637486261\n",
      "Epoch 7/15  loss=0.0952  val_loss=0.0964  f1=0.688  time=162.97s\n",
      "model_saved at f1: 0.6878664287535049 from 0.6851287209631284\n",
      "Epoch 8/15  loss=0.0933  val_loss=0.0956  f1=0.689  time=154.39s\n",
      "model_saved at f1: 0.6891830804003874 from 0.6878664287535049\n",
      "Epoch 9/15  loss=0.0914  val_loss=0.0963  f1=0.687  time=155.10s\n",
      "Epoch 10/15  loss=0.0902  val_loss=0.0966  f1=0.687  time=155.18s\n",
      "Epoch 11/15  loss=0.0886  val_loss=0.0970  f1=0.688  time=159.22s\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0968  f1=0.687  time=157.63s\n",
      "Epoch 13/15  loss=0.0859  val_loss=0.0969  f1=0.689  time=155.28s\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0956  f1=0.687  time=150.36s\n",
      "Epoch 15/15  loss=0.0838  val_loss=0.0981  f1=0.686  time=154.49s\n",
      "Fold 5\n",
      "Epoch 1/15  loss=0.1627  val_loss=0.1110  f1=0.641  time=162.81s\n",
      "model_saved at f1: 0.6405434992594501 from 0.0\n",
      "Epoch 2/15  loss=0.1117  val_loss=0.1042  f1=0.662  time=155.49s\n",
      "model_saved at f1: 0.6615861704935339 from 0.6405434992594501\n",
      "Epoch 3/15  loss=0.1063  val_loss=0.1008  f1=0.673  time=155.75s\n",
      "model_saved at f1: 0.6733354985384866 from 0.6615861704935339\n",
      "Epoch 4/15  loss=0.1030  val_loss=0.0994  f1=0.677  time=154.87s\n",
      "model_saved at f1: 0.6772639994963644 from 0.6733354985384866\n",
      "Epoch 5/15  loss=0.1000  val_loss=0.0979  f1=0.683  time=158.92s\n",
      "model_saved at f1: 0.6830182475752096 from 0.6772639994963644\n",
      "Epoch 6/15  loss=0.0977  val_loss=0.0988  f1=0.686  time=159.98s\n",
      "model_saved at f1: 0.6863023420865861 from 0.6830182475752096\n",
      "Epoch 7/15  loss=0.0953  val_loss=0.0973  f1=0.687  time=154.67s\n",
      "model_saved at f1: 0.6872751063133792 from 0.6863023420865861\n",
      "Epoch 8/15  loss=0.0935  val_loss=0.0974  f1=0.687  time=156.17s\n",
      "Epoch 9/15  loss=0.0917  val_loss=0.0969  f1=0.691  time=154.97s\n",
      "model_saved at f1: 0.6907620371540503 from 0.6872751063133792\n",
      "Epoch 10/15  loss=0.0901  val_loss=0.0966  f1=0.690  time=163.24s\n",
      "Epoch 11/15  loss=0.0889  val_loss=0.0983  f1=0.690  time=156.08s\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0967  f1=0.691  time=155.88s\n",
      "model_saved at f1: 0.6908333604503596 from 0.6907620371540503\n",
      "Epoch 13/15  loss=0.0863  val_loss=0.0965  f1=0.691  time=155.68s\n",
      "model_saved at f1: 0.6912962200183771 from 0.6908333604503596\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0976  f1=0.690  time=154.04s\n",
      "Epoch 15/15  loss=0.0839  val_loss=0.0982  f1=0.691  time=163.70s\n",
      "{'threshold': 0.2833130955696106, 'f1': 0.6900286795484069}\n",
      "f1 score: 0.7033704097032027\n"
     ]
    }
   ],
   "source": [
    "train_preds, test_preds = training(train_x, train_y, test_x, c, embeddings)\n",
    "search_result = threshold_search(train_y, train_preds)\n",
    "print(search_result)\n",
    "test_pred_targets = test_preds > search_result['threshold']\n",
    "f1 = f1_score(test_df['target'], test_pred_targets)\n",
    "print('f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15  loss=0.1621  val_loss=0.1129  f1=0.640  time=155.60s\n",
      "model_saved at f1: 0.6404416839199447 from 0.0\n",
      "Epoch 2/15  loss=0.1123  val_loss=0.1033  f1=0.666  time=153.44s\n",
      "model_saved at f1: 0.6656712542196832 from 0.6404416839199447\n",
      "Epoch 3/15  loss=0.1065  val_loss=0.1013  f1=0.673  time=151.36s\n",
      "model_saved at f1: 0.672926852961176 from 0.6656712542196832\n",
      "Epoch 4/15  loss=0.1029  val_loss=0.0991  f1=0.678  time=161.10s\n",
      "model_saved at f1: 0.6783554631258998 from 0.672926852961176\n",
      "Epoch 5/15  loss=0.1002  val_loss=0.0977  f1=0.683  time=155.86s\n",
      "model_saved at f1: 0.6831843503044436 from 0.6783554631258998\n",
      "Epoch 6/15  loss=0.0974  val_loss=0.0967  f1=0.686  time=154.79s\n",
      "model_saved at f1: 0.6864211737629459 from 0.6831843503044436\n",
      "Epoch 7/15  loss=0.0956  val_loss=0.0963  f1=0.690  time=155.59s\n",
      "model_saved at f1: 0.6897332988089072 from 0.6864211737629459\n",
      "Epoch 8/15  loss=0.0937  val_loss=0.0967  f1=0.691  time=153.72s\n",
      "model_saved at f1: 0.6910753685287627 from 0.6897332988089072\n",
      "Epoch 9/15  loss=0.0920  val_loss=0.0962  f1=0.691  time=162.39s\n",
      "Epoch 10/15  loss=0.0904  val_loss=0.0967  f1=0.693  time=155.18s\n",
      "model_saved at f1: 0.6928293639314757 from 0.6910753685287627\n",
      "Epoch 11/15  loss=0.0889  val_loss=0.0964  f1=0.692  time=155.05s\n",
      "Epoch 12/15  loss=0.0874  val_loss=0.0973  f1=0.691  time=154.44s\n",
      "Epoch 13/15  loss=0.0861  val_loss=0.0969  f1=0.693  time=157.57s\n",
      "model_saved at f1: 0.6932921731301047 from 0.6928293639314757\n",
      "Epoch 14/15  loss=0.0852  val_loss=0.0978  f1=0.692  time=158.94s\n",
      "Epoch 15/15  loss=0.0837  val_loss=0.0978  f1=0.692  time=154.58s\n",
      "Fold 2\n",
      "Epoch 1/15  loss=0.1420  val_loss=0.1081  f1=0.648  time=153.85s\n",
      "model_saved at f1: 0.6475863631948716 from 0.0\n",
      "Epoch 2/15  loss=0.1103  val_loss=0.1035  f1=0.664  time=154.96s\n",
      "model_saved at f1: 0.6637892448366264 from 0.6475863631948716\n",
      "Epoch 3/15  loss=0.1049  val_loss=0.1026  f1=0.671  time=162.18s\n",
      "model_saved at f1: 0.671026029820571 from 0.6637892448366264\n",
      "Epoch 4/15  loss=0.1019  val_loss=0.1007  f1=0.680  time=155.36s\n",
      "model_saved at f1: 0.6799224054316197 from 0.671026029820571\n",
      "Epoch 5/15  loss=0.0995  val_loss=0.0994  f1=0.681  time=155.36s\n",
      "model_saved at f1: 0.6809031916302476 from 0.6799224054316197\n",
      "Epoch 6/15  loss=0.0970  val_loss=0.0992  f1=0.685  time=155.01s\n",
      "model_saved at f1: 0.6853396142338787 from 0.6809031916302476\n",
      "Epoch 7/15  loss=0.0953  val_loss=0.0973  f1=0.684  time=150.95s\n",
      "Epoch 8/15  loss=0.0936  val_loss=0.0976  f1=0.686  time=161.67s\n",
      "model_saved at f1: 0.686492950654582 from 0.6853396142338787\n",
      "Epoch 9/15  loss=0.0916  val_loss=0.0973  f1=0.689  time=155.48s\n",
      "model_saved at f1: 0.6891900530588762 from 0.686492950654582\n",
      "Epoch 10/15  loss=0.0899  val_loss=0.0977  f1=0.685  time=155.39s\n",
      "Epoch 11/15  loss=0.0887  val_loss=0.0973  f1=0.690  time=155.03s\n",
      "model_saved at f1: 0.6901978417266187 from 0.6891900530588762\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0989  f1=0.690  time=163.52s\n",
      "Epoch 13/15  loss=0.0862  val_loss=0.0990  f1=0.686  time=154.50s\n",
      "Epoch 14/15  loss=0.0848  val_loss=0.0998  f1=0.687  time=155.00s\n",
      "Epoch 15/15  loss=0.0838  val_loss=0.0989  f1=0.689  time=156.12s\n",
      "Fold 3\n",
      "Epoch 1/15  loss=0.1666  val_loss=0.1087  f1=0.648  time=154.45s\n",
      "model_saved at f1: 0.6483971703524314 from 0.0\n",
      "Epoch 2/15  loss=0.1117  val_loss=0.1038  f1=0.662  time=161.98s\n",
      "model_saved at f1: 0.6622825488354012 from 0.6483971703524314\n",
      "Epoch 3/15  loss=0.1059  val_loss=0.1011  f1=0.672  time=153.80s\n",
      "model_saved at f1: 0.6721528382870234 from 0.6622825488354012\n",
      "Epoch 4/15  loss=0.1023  val_loss=0.0992  f1=0.681  time=154.48s\n",
      "model_saved at f1: 0.6806549038308695 from 0.6721528382870234\n",
      "Epoch 5/15  loss=0.0994  val_loss=0.0981  f1=0.683  time=155.34s\n",
      "model_saved at f1: 0.6829873933528587 from 0.6806549038308695\n",
      "Epoch 6/15  loss=0.0967  val_loss=0.0974  f1=0.686  time=154.78s\n",
      "model_saved at f1: 0.6860442609200594 from 0.6829873933528587\n",
      "Epoch 7/15  loss=0.0951  val_loss=0.0963  f1=0.688  time=160.84s\n",
      "model_saved at f1: 0.6878590578322483 from 0.6860442609200594\n",
      "Epoch 8/15  loss=0.0930  val_loss=0.0981  f1=0.686  time=154.94s\n",
      "Epoch 9/15  loss=0.0915  val_loss=0.0966  f1=0.692  time=155.02s\n",
      "model_saved at f1: 0.6916037373608089 from 0.6878590578322483\n",
      "Epoch 10/15  loss=0.0901  val_loss=0.0965  f1=0.691  time=155.16s\n",
      "Epoch 11/15  loss=0.0886  val_loss=0.0976  f1=0.690  time=162.82s\n",
      "Epoch 12/15  loss=0.0874  val_loss=0.0971  f1=0.691  time=149.71s\n",
      "Epoch 13/15  loss=0.0861  val_loss=0.0974  f1=0.693  time=154.14s\n",
      "model_saved at f1: 0.6925312130791583 from 0.6916037373608089\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0982  f1=0.692  time=155.19s\n",
      "Epoch 15/15  loss=0.0839  val_loss=0.0991  f1=0.689  time=157.43s\n",
      "Fold 4\n",
      "Epoch 1/15  loss=0.1628  val_loss=0.1101  f1=0.646  time=163.27s\n",
      "model_saved at f1: 0.6462158808933003 from 0.0\n",
      "Epoch 2/15  loss=0.1118  val_loss=0.1033  f1=0.666  time=155.05s\n",
      "model_saved at f1: 0.6661907852044127 from 0.6462158808933003\n",
      "Epoch 3/15  loss=0.1063  val_loss=0.1024  f1=0.669  time=154.39s\n",
      "model_saved at f1: 0.6694888280603475 from 0.6661907852044127\n",
      "Epoch 4/15  loss=0.1026  val_loss=0.0987  f1=0.681  time=155.39s\n",
      "model_saved at f1: 0.6809558847052049 from 0.6694888280603475\n",
      "Epoch 5/15  loss=0.0999  val_loss=0.0982  f1=0.682  time=161.19s\n",
      "model_saved at f1: 0.6816919393455706 from 0.6809558847052049\n",
      "Epoch 6/15  loss=0.0976  val_loss=0.0968  f1=0.685  time=155.84s\n",
      "model_saved at f1: 0.6849473785845323 from 0.6816919393455706\n",
      "Epoch 7/15  loss=0.0955  val_loss=0.0964  f1=0.688  time=155.48s\n",
      "model_saved at f1: 0.6879157785958794 from 0.6849473785845323\n",
      "Epoch 8/15  loss=0.0937  val_loss=0.0970  f1=0.690  time=155.56s\n",
      "model_saved at f1: 0.6903880520806739 from 0.6879157785958794\n",
      "Epoch 9/15  loss=0.0919  val_loss=0.0974  f1=0.690  time=154.15s\n",
      "Epoch 10/15  loss=0.0902  val_loss=0.0957  f1=0.691  time=162.34s\n",
      "model_saved at f1: 0.6905224284486325 from 0.6903880520806739\n",
      "Epoch 11/15  loss=0.0886  val_loss=0.0969  f1=0.692  time=154.47s\n",
      "model_saved at f1: 0.6918495397649457 from 0.6905224284486325\n",
      "Epoch 12/15  loss=0.0875  val_loss=0.0985  f1=0.690  time=155.12s\n",
      "Epoch 13/15  loss=0.0862  val_loss=0.0979  f1=0.690  time=155.65s\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0977  f1=0.692  time=158.69s\n",
      "model_saved at f1: 0.6922678744742801 from 0.6918495397649457\n",
      "Epoch 15/15  loss=0.0838  val_loss=0.0988  f1=0.693  time=159.19s\n",
      "model_saved at f1: 0.6926792069140824 from 0.6922678744742801\n",
      "Fold 5\n",
      "Epoch 1/15  loss=0.1524  val_loss=0.1100  f1=0.650  time=151.17s\n",
      "model_saved at f1: 0.6502860114404576 from 0.0\n",
      "Epoch 2/15  loss=0.1114  val_loss=0.1036  f1=0.667  time=154.44s\n",
      "model_saved at f1: 0.6672458172458172 from 0.6502860114404576\n",
      "Epoch 3/15  loss=0.1061  val_loss=0.1011  f1=0.672  time=153.90s\n",
      "model_saved at f1: 0.6718307073637022 from 0.6672458172458172\n",
      "Epoch 4/15  loss=0.1026  val_loss=0.0991  f1=0.681  time=163.45s\n",
      "model_saved at f1: 0.6811340339950694 from 0.6718307073637022\n",
      "Epoch 5/15  loss=0.0998  val_loss=0.0976  f1=0.683  time=155.27s\n",
      "model_saved at f1: 0.6833526991803536 from 0.6811340339950694\n",
      "Epoch 6/15  loss=0.0974  val_loss=0.0972  f1=0.687  time=153.62s\n",
      "model_saved at f1: 0.6868345553076188 from 0.6833526991803536\n",
      "Epoch 7/15  loss=0.0954  val_loss=0.0975  f1=0.690  time=154.46s\n",
      "model_saved at f1: 0.6898920828337168 from 0.6868345553076188\n",
      "Epoch 8/15  loss=0.0935  val_loss=0.0958  f1=0.689  time=153.69s\n",
      "Epoch 9/15  loss=0.0919  val_loss=0.0970  f1=0.691  time=162.75s\n",
      "model_saved at f1: 0.6914045985235291 from 0.6898920828337168\n",
      "Epoch 10/15  loss=0.0904  val_loss=0.0961  f1=0.690  time=155.70s\n",
      "Epoch 11/15  loss=0.0890  val_loss=0.0963  f1=0.691  time=154.24s\n",
      "Epoch 12/15  loss=0.0874  val_loss=0.0961  f1=0.693  time=154.48s\n",
      "model_saved at f1: 0.6930711787503544 from 0.6914045985235291\n",
      "Epoch 13/15  loss=0.0863  val_loss=0.0960  f1=0.691  time=161.76s\n",
      "Epoch 14/15  loss=0.0852  val_loss=0.0960  f1=0.691  time=156.43s\n",
      "Epoch 15/15  loss=0.0840  val_loss=0.0959  f1=0.692  time=154.42s\n",
      "{'threshold': 0.3151057958602905, 'f1': 0.6896694188200815}\n",
      "f1 score: 0.7019921241602965\n"
     ]
    }
   ],
   "source": [
    "train_preds, test_preds = training(train_x, train_y, test_x, c, embeddings)\n",
    "search_result = threshold_search(train_y, train_preds)\n",
    "print(search_result)\n",
    "test_pred_targets = test_preds > search_result['threshold']\n",
    "f1 = f1_score(test_df['target'], test_pred_targets)\n",
    "print('f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15  loss=0.1656  val_loss=0.1145  f1=0.629  time=155.18s\n",
      "model_saved at f1: 0.6292715965765655 from 0.0\n",
      "Epoch 2/15  loss=0.1149  val_loss=0.1069  f1=0.652  time=155.52s\n",
      "model_saved at f1: 0.6517478052673584 from 0.6292715965765655\n",
      "Epoch 3/15  loss=0.1092  val_loss=0.1038  f1=0.663  time=162.95s\n",
      "model_saved at f1: 0.6625782386040335 from 0.6517478052673584\n",
      "Epoch 4/15  loss=0.1051  val_loss=0.1013  f1=0.673  time=155.10s\n",
      "model_saved at f1: 0.6726489129036408 from 0.6625782386040335\n",
      "Epoch 5/15  loss=0.1022  val_loss=0.0999  f1=0.677  time=150.45s\n",
      "model_saved at f1: 0.6768259286703824 from 0.6726489129036408\n",
      "Epoch 6/15  loss=0.0996  val_loss=0.0987  f1=0.681  time=154.75s\n",
      "model_saved at f1: 0.6813129331764091 from 0.6768259286703824\n",
      "Epoch 7/15  loss=0.0975  val_loss=0.0980  f1=0.685  time=157.39s\n",
      "model_saved at f1: 0.6849251862105333 from 0.6813129331764091\n",
      "Epoch 8/15  loss=0.0953  val_loss=0.0976  f1=0.685  time=160.35s\n",
      "model_saved at f1: 0.6853771328336788 from 0.6849251862105333\n",
      "Epoch 9/15  loss=0.0935  val_loss=0.0980  f1=0.686  time=155.05s\n",
      "model_saved at f1: 0.6860872032535704 from 0.6853771328336788\n",
      "Epoch 10/15  loss=0.0918  val_loss=0.0966  f1=0.690  time=153.76s\n",
      "model_saved at f1: 0.6895109920621957 from 0.6860872032535704\n",
      "Epoch 11/15  loss=0.0904  val_loss=0.0972  f1=0.689  time=155.11s\n",
      "Epoch 12/15  loss=0.0886  val_loss=0.0971  f1=0.690  time=163.28s\n",
      "model_saved at f1: 0.6897794071171228 from 0.6895109920621957\n",
      "Epoch 13/15  loss=0.0876  val_loss=0.0968  f1=0.691  time=154.88s\n",
      "model_saved at f1: 0.6908556499020247 from 0.6897794071171228\n",
      "Epoch 14/15  loss=0.0862  val_loss=0.0972  f1=0.691  time=154.59s\n",
      "model_saved at f1: 0.6909703860391329 from 0.6908556499020247\n",
      "Epoch 15/15  loss=0.0851  val_loss=0.0977  f1=0.689  time=155.15s\n",
      "Fold 2\n",
      "Epoch 1/15  loss=0.1787  val_loss=0.1117  f1=0.638  time=154.85s\n",
      "model_saved at f1: 0.6383083353823457 from 0.0\n",
      "Epoch 2/15  loss=0.1134  val_loss=0.1046  f1=0.660  time=163.83s\n",
      "model_saved at f1: 0.6598645882538182 from 0.6383083353823457\n",
      "Epoch 3/15  loss=0.1073  val_loss=0.1023  f1=0.666  time=153.63s\n",
      "model_saved at f1: 0.6657958455460685 from 0.6598645882538182\n",
      "Epoch 4/15  loss=0.1036  val_loss=0.0996  f1=0.678  time=154.51s\n",
      "model_saved at f1: 0.6781793511779943 from 0.6657958455460685\n",
      "Epoch 5/15  loss=0.1005  val_loss=0.0985  f1=0.679  time=155.55s\n",
      "model_saved at f1: 0.6785484078896479 from 0.6781793511779943\n",
      "Epoch 6/15  loss=0.0981  val_loss=0.0982  f1=0.680  time=156.04s\n",
      "model_saved at f1: 0.6795307391499454 from 0.6785484078896479\n",
      "Epoch 7/15  loss=0.0960  val_loss=0.0966  f1=0.686  time=160.50s\n",
      "model_saved at f1: 0.6860776655153491 from 0.6795307391499454\n",
      "Epoch 8/15  loss=0.0939  val_loss=0.0985  f1=0.686  time=155.67s\n",
      "Epoch 9/15  loss=0.0924  val_loss=0.0963  f1=0.686  time=150.06s\n",
      "Epoch 10/15  loss=0.0910  val_loss=0.0967  f1=0.687  time=154.69s\n",
      "model_saved at f1: 0.6871401151631478 from 0.6860776655153491\n",
      "Epoch 11/15  loss=0.0892  val_loss=0.0974  f1=0.688  time=162.30s\n",
      "model_saved at f1: 0.6876643787285907 from 0.6871401151631478\n",
      "Epoch 12/15  loss=0.0881  val_loss=0.0983  f1=0.687  time=154.40s\n",
      "Epoch 13/15  loss=0.0867  val_loss=0.0985  f1=0.690  time=155.61s\n",
      "model_saved at f1: 0.6898846495119787 from 0.6876643787285907\n",
      "Epoch 14/15  loss=0.0858  val_loss=0.0971  f1=0.688  time=154.37s\n",
      "Epoch 15/15  loss=0.0845  val_loss=0.0973  f1=0.689  time=155.66s\n",
      "Fold 3\n",
      "Epoch 1/15  loss=0.1514  val_loss=0.1112  f1=0.642  time=161.62s\n",
      "model_saved at f1: 0.6416096219051883 from 0.0\n",
      "Epoch 2/15  loss=0.1117  val_loss=0.1043  f1=0.661  time=155.85s\n",
      "model_saved at f1: 0.6607714493993851 from 0.6416096219051883\n",
      "Epoch 3/15  loss=0.1058  val_loss=0.1015  f1=0.673  time=155.69s\n",
      "model_saved at f1: 0.6728015034670468 from 0.6607714493993851\n",
      "Epoch 4/15  loss=0.1022  val_loss=0.0995  f1=0.677  time=154.79s\n",
      "model_saved at f1: 0.6769310389442361 from 0.6728015034670468\n",
      "Epoch 5/15  loss=0.0992  val_loss=0.0982  f1=0.682  time=158.43s\n",
      "model_saved at f1: 0.6819172822231623 from 0.6769310389442361\n",
      "Epoch 6/15  loss=0.0968  val_loss=0.0994  f1=0.685  time=158.57s\n",
      "model_saved at f1: 0.6848116333687225 from 0.6819172822231623\n",
      "Epoch 7/15  loss=0.0949  val_loss=0.0981  f1=0.687  time=154.74s\n",
      "model_saved at f1: 0.6871965327337309 from 0.6848116333687225\n",
      "Epoch 8/15  loss=0.0930  val_loss=0.0985  f1=0.689  time=155.34s\n",
      "model_saved at f1: 0.6885014741699783 from 0.6871965327337309\n",
      "Epoch 9/15  loss=0.0914  val_loss=0.0966  f1=0.690  time=154.72s\n",
      "model_saved at f1: 0.6897681121446352 from 0.6885014741699783\n",
      "Epoch 10/15  loss=0.0897  val_loss=0.0977  f1=0.689  time=162.48s\n",
      "Epoch 11/15  loss=0.0880  val_loss=0.0979  f1=0.691  time=155.93s\n",
      "model_saved at f1: 0.6909162795295047 from 0.6897681121446352\n",
      "Epoch 12/15  loss=0.0871  val_loss=0.0987  f1=0.691  time=155.37s\n",
      "Epoch 13/15  loss=0.0856  val_loss=0.0975  f1=0.690  time=151.05s\n",
      "Epoch 14/15  loss=0.0842  val_loss=0.0989  f1=0.690  time=157.77s\n",
      "Epoch 15/15  loss=0.0833  val_loss=0.0982  f1=0.692  time=160.05s\n",
      "model_saved at f1: 0.6920890108812862 from 0.6909162795295047\n",
      "Fold 4\n",
      "Epoch 1/15  loss=0.1517  val_loss=0.1119  f1=0.643  time=154.53s\n",
      "model_saved at f1: 0.6428933046449816 from 0.0\n",
      "Epoch 2/15  loss=0.1117  val_loss=0.1039  f1=0.661  time=155.74s\n",
      "model_saved at f1: 0.6613608193619935 from 0.6428933046449816\n",
      "Epoch 3/15  loss=0.1061  val_loss=0.1015  f1=0.674  time=155.66s\n",
      "model_saved at f1: 0.6739338305603365 from 0.6613608193619935\n",
      "Epoch 4/15  loss=0.1028  val_loss=0.0984  f1=0.682  time=160.00s\n",
      "model_saved at f1: 0.6820543883699429 from 0.6739338305603365\n",
      "Epoch 5/15  loss=0.1000  val_loss=0.0980  f1=0.684  time=156.32s\n",
      "model_saved at f1: 0.6840458811261731 from 0.6820543883699429\n",
      "Epoch 6/15  loss=0.0975  val_loss=0.0972  f1=0.689  time=155.82s\n",
      "model_saved at f1: 0.6890224203657039 from 0.6840458811261731\n",
      "Epoch 7/15  loss=0.0956  val_loss=0.0964  f1=0.692  time=155.10s\n",
      "model_saved at f1: 0.6917610908392549 from 0.6890224203657039\n",
      "Epoch 8/15  loss=0.0934  val_loss=0.0967  f1=0.691  time=154.67s\n",
      "Epoch 9/15  loss=0.0914  val_loss=0.0964  f1=0.692  time=162.94s\n",
      "model_saved at f1: 0.6920360678479098 from 0.6917610908392549\n",
      "Epoch 10/15  loss=0.0902  val_loss=0.0968  f1=0.691  time=154.40s\n",
      "Epoch 11/15  loss=0.0888  val_loss=0.0976  f1=0.691  time=155.19s\n",
      "Epoch 12/15  loss=0.0873  val_loss=0.0989  f1=0.690  time=154.39s\n",
      "Epoch 13/15  loss=0.0861  val_loss=0.0968  f1=0.692  time=157.64s\n",
      "Epoch 14/15  loss=0.0848  val_loss=0.0998  f1=0.693  time=158.64s\n",
      "model_saved at f1: 0.6929855256879275 from 0.6920360678479098\n",
      "Epoch 15/15  loss=0.0839  val_loss=0.0970  f1=0.693  time=155.57s\n",
      "model_saved at f1: 0.6931677826171748 from 0.6929855256879275\n",
      "Fold 5\n",
      "Epoch 1/15  loss=0.1511  val_loss=0.1102  f1=0.648  time=154.33s\n",
      "model_saved at f1: 0.6484390149311615 from 0.0\n",
      "Epoch 2/15  loss=0.1118  val_loss=0.1021  f1=0.668  time=149.12s\n",
      "model_saved at f1: 0.6681537855924419 from 0.6484390149311615\n",
      "Epoch 3/15  loss=0.1064  val_loss=0.1006  f1=0.676  time=163.56s\n",
      "model_saved at f1: 0.6760843103337817 from 0.6681537855924419\n",
      "Epoch 4/15  loss=0.1027  val_loss=0.0971  f1=0.685  time=155.04s\n",
      "model_saved at f1: 0.684684097281085 from 0.6760843103337817\n",
      "Epoch 5/15  loss=0.1000  val_loss=0.0979  f1=0.687  time=153.74s\n",
      "model_saved at f1: 0.6866293034427542 from 0.684684097281085\n",
      "Epoch 6/15  loss=0.0976  val_loss=0.0985  f1=0.687  time=154.92s\n",
      "model_saved at f1: 0.6872814042428006 from 0.6866293034427542\n",
      "Epoch 7/15  loss=0.0953  val_loss=0.0951  f1=0.689  time=154.56s\n",
      "model_saved at f1: 0.6886069257203278 from 0.6872814042428006\n",
      "Epoch 8/15  loss=0.0935  val_loss=0.0955  f1=0.689  time=161.29s\n",
      "model_saved at f1: 0.6889974107698863 from 0.6886069257203278\n",
      "Epoch 9/15  loss=0.0917  val_loss=0.0951  f1=0.694  time=155.38s\n",
      "model_saved at f1: 0.6935101231679178 from 0.6889974107698863\n",
      "Epoch 10/15  loss=0.0902  val_loss=0.0956  f1=0.691  time=155.00s\n",
      "Epoch 11/15  loss=0.0887  val_loss=0.0954  f1=0.694  time=154.80s\n",
      "model_saved at f1: 0.693698492777238 from 0.6935101231679178\n",
      "Epoch 12/15  loss=0.0875  val_loss=0.0949  f1=0.694  time=162.67s\n",
      "Epoch 13/15  loss=0.0860  val_loss=0.0977  f1=0.690  time=155.04s\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0985  f1=0.693  time=155.27s\n",
      "Epoch 15/15  loss=0.0838  val_loss=0.0973  f1=0.690  time=156.04s\n",
      "{'threshold': 0.3202049136161804, 'f1': 0.6900586300770365}\n",
      "f1 score: 0.7049675023212627\n"
     ]
    }
   ],
   "source": [
    "train_preds, test_preds = training(train_x, train_y, test_x, c, embeddings)\n",
    "search_result = threshold_search(train_y, train_preds)\n",
    "print(search_result)\n",
    "test_pred_targets = test_preds > search_result['threshold']\n",
    "f1 = f1_score(test_df['target'], test_pred_targets)\n",
    "print('f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.local/share/virtualenvs/data_aug-A9JyLOeQ/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15  loss=0.1590  val_loss=0.1087  f1=0.647  time=155.56s\n",
      "model_saved at f1: 0.6466224643865293 from 0.0\n",
      "Epoch 2/15  loss=0.1109  val_loss=0.1034  f1=0.664  time=162.60s\n",
      "model_saved at f1: 0.6642998784622275 from 0.6466224643865293\n",
      "Epoch 3/15  loss=0.1057  val_loss=0.1012  f1=0.672  time=155.92s\n",
      "model_saved at f1: 0.6719669058237994 from 0.6642998784622275\n",
      "Epoch 4/15  loss=0.1023  val_loss=0.0994  f1=0.679  time=156.57s\n",
      "model_saved at f1: 0.6790556861734678 from 0.6719669058237994\n",
      "Epoch 5/15  loss=0.0994  val_loss=0.0986  f1=0.679  time=155.59s\n",
      "Epoch 6/15  loss=0.0972  val_loss=0.0980  f1=0.683  time=151.13s\n",
      "model_saved at f1: 0.6825599267471141 from 0.6790556861734678\n",
      "Epoch 7/15  loss=0.0952  val_loss=0.0971  f1=0.685  time=162.79s\n",
      "model_saved at f1: 0.6852251109701966 from 0.6825599267471141\n",
      "Epoch 8/15  loss=0.0936  val_loss=0.0971  f1=0.689  time=155.92s\n",
      "model_saved at f1: 0.6889305573516099 from 0.6852251109701966\n",
      "Epoch 9/15  loss=0.0919  val_loss=0.0967  f1=0.692  time=155.51s\n",
      "model_saved at f1: 0.691673825204416 from 0.6889305573516099\n",
      "Epoch 10/15  loss=0.0901  val_loss=0.0980  f1=0.690  time=154.81s\n",
      "Epoch 11/15  loss=0.0891  val_loss=0.0975  f1=0.690  time=161.00s\n",
      "Epoch 12/15  loss=0.0875  val_loss=0.0976  f1=0.688  time=158.29s\n",
      "Epoch 13/15  loss=0.0865  val_loss=0.0978  f1=0.688  time=155.88s\n",
      "Epoch 14/15  loss=0.0854  val_loss=0.0996  f1=0.688  time=155.32s\n",
      "Epoch 15/15  loss=0.0840  val_loss=0.0988  f1=0.688  time=154.82s\n",
      "Fold 2\n",
      "Epoch 1/15  loss=0.1555  val_loss=0.1115  f1=0.637  time=160.95s\n",
      "model_saved at f1: 0.6365086813702486 from 0.0\n",
      "Epoch 2/15  loss=0.1125  val_loss=0.1049  f1=0.658  time=156.75s\n",
      "model_saved at f1: 0.6581381994512856 from 0.6365086813702486\n",
      "Epoch 3/15  loss=0.1065  val_loss=0.1018  f1=0.668  time=155.89s\n",
      "model_saved at f1: 0.6683255175933901 from 0.6581381994512856\n",
      "Epoch 4/15  loss=0.1027  val_loss=0.0994  f1=0.675  time=155.00s\n",
      "model_saved at f1: 0.6747838711806243 from 0.6683255175933901\n",
      "Epoch 5/15  loss=0.0997  val_loss=0.0996  f1=0.678  time=153.66s\n",
      "model_saved at f1: 0.6776640733447397 from 0.6747838711806243\n",
      "Epoch 6/15  loss=0.0973  val_loss=0.0974  f1=0.683  time=163.35s\n",
      "model_saved at f1: 0.682987631435968 from 0.6776640733447397\n",
      "Epoch 7/15  loss=0.0950  val_loss=0.0976  f1=0.684  time=154.24s\n",
      "model_saved at f1: 0.6842835478979123 from 0.682987631435968\n",
      "Epoch 8/15  loss=0.0932  val_loss=0.0970  f1=0.685  time=154.35s\n",
      "model_saved at f1: 0.6853895891842466 from 0.6842835478979123\n",
      "Epoch 9/15  loss=0.0913  val_loss=0.0968  f1=0.690  time=155.26s\n",
      "model_saved at f1: 0.6895040954981269 from 0.6853895891842466\n",
      "Epoch 10/15  loss=0.0897  val_loss=0.0979  f1=0.688  time=155.40s\n",
      "Epoch 11/15  loss=0.0881  val_loss=0.0976  f1=0.688  time=156.48s\n",
      "Epoch 12/15  loss=0.0867  val_loss=0.0983  f1=0.685  time=155.82s\n",
      "Epoch 13/15  loss=0.0854  val_loss=0.0981  f1=0.687  time=154.85s\n",
      "Epoch 14/15  loss=0.0840  val_loss=0.0993  f1=0.685  time=154.35s\n",
      "Epoch 15/15  loss=0.0828  val_loss=0.1008  f1=0.687  time=163.60s\n",
      "Fold 3\n",
      "Epoch 1/15  loss=0.1457  val_loss=0.1104  f1=0.647  time=154.04s\n",
      "model_saved at f1: 0.6466968384723082 from 0.0\n",
      "Epoch 2/15  loss=0.1108  val_loss=0.1040  f1=0.664  time=154.89s\n",
      "model_saved at f1: 0.6644702161307326 from 0.6466968384723082\n",
      "Epoch 3/15  loss=0.1058  val_loss=0.1003  f1=0.676  time=154.70s\n",
      "model_saved at f1: 0.6758335979676087 from 0.6644702161307326\n",
      "Epoch 4/15  loss=0.1021  val_loss=0.0987  f1=0.682  time=154.14s\n",
      "model_saved at f1: 0.6821832383232024 from 0.6758335979676087\n",
      "Epoch 5/15  loss=0.0996  val_loss=0.0987  f1=0.684  time=162.84s\n",
      "model_saved at f1: 0.684086752025085 from 0.6821832383232024\n",
      "Epoch 6/15  loss=0.0972  val_loss=0.0991  f1=0.686  time=155.97s\n",
      "model_saved at f1: 0.686429554694753 from 0.684086752025085\n",
      "Epoch 7/15  loss=0.0953  val_loss=0.0963  f1=0.689  time=155.01s\n",
      "model_saved at f1: 0.6886501093810321 from 0.686429554694753\n",
      "Epoch 8/15  loss=0.0935  val_loss=0.0963  f1=0.689  time=155.85s\n",
      "model_saved at f1: 0.6892127888232134 from 0.6886501093810321\n",
      "Epoch 9/15  loss=0.0916  val_loss=0.0960  f1=0.692  time=161.25s\n",
      "model_saved at f1: 0.6915863674578026 from 0.6892127888232134\n",
      "Epoch 10/15  loss=0.0901  val_loss=0.0963  f1=0.691  time=158.06s\n",
      "Epoch 11/15  loss=0.0888  val_loss=0.0983  f1=0.691  time=155.44s\n",
      "Epoch 12/15  loss=0.0875  val_loss=0.0963  f1=0.693  time=155.22s\n",
      "model_saved at f1: 0.6929008917520866 from 0.6915863674578026\n",
      "Epoch 13/15  loss=0.0860  val_loss=0.0961  f1=0.692  time=154.30s\n",
      "Epoch 14/15  loss=0.0847  val_loss=0.0970  f1=0.691  time=162.36s\n",
      "Epoch 15/15  loss=0.0836  val_loss=0.0976  f1=0.690  time=151.20s\n",
      "Fold 4\n",
      "Epoch 1/15  loss=0.1528  val_loss=0.1167  f1=0.647  time=155.85s\n",
      "model_saved at f1: 0.6472489795918368 from 0.0\n",
      "Epoch 2/15  loss=0.1113  val_loss=0.1041  f1=0.666  time=155.49s\n",
      "model_saved at f1: 0.6662975868694435 from 0.6472489795918368\n",
      "Epoch 3/15  loss=0.1060  val_loss=0.1006  f1=0.674  time=155.03s\n",
      "model_saved at f1: 0.6743708609271524 from 0.6662975868694435\n",
      "Epoch 4/15  loss=0.1025  val_loss=0.0990  f1=0.680  time=162.51s\n",
      "model_saved at f1: 0.6798131811105345 from 0.6743708609271524\n",
      "Epoch 5/15  loss=0.0997  val_loss=0.0980  f1=0.685  time=154.96s\n",
      "model_saved at f1: 0.6853302737256188 from 0.6798131811105345\n",
      "Epoch 6/15  loss=0.0973  val_loss=0.0994  f1=0.685  time=154.71s\n",
      "Epoch 7/15  loss=0.0950  val_loss=0.0982  f1=0.684  time=155.34s\n",
      "Epoch 8/15  loss=0.0932  val_loss=0.0968  f1=0.688  time=162.57s\n",
      "model_saved at f1: 0.6879111434332749 from 0.6853302737256188\n",
      "Epoch 9/15  loss=0.0914  val_loss=0.0972  f1=0.689  time=155.91s\n",
      "model_saved at f1: 0.6892731781148359 from 0.6879111434332749\n",
      "Epoch 10/15  loss=0.0899  val_loss=0.0978  f1=0.689  time=154.61s\n",
      "Epoch 11/15  loss=0.0883  val_loss=0.0985  f1=0.689  time=155.31s\n",
      "Epoch 12/15  loss=0.0871  val_loss=0.0988  f1=0.688  time=153.96s\n",
      "Epoch 13/15  loss=0.0860  val_loss=0.0975  f1=0.690  time=163.39s\n",
      "model_saved at f1: 0.6895044668680507 from 0.6892731781148359\n",
      "Epoch 14/15  loss=0.0847  val_loss=0.0982  f1=0.688  time=154.37s\n",
      "Epoch 15/15  loss=0.0837  val_loss=0.0988  f1=0.688  time=154.84s\n",
      "Fold 5\n",
      "Epoch 1/15  loss=0.1475  val_loss=0.1092  f1=0.649  time=155.74s\n",
      "model_saved at f1: 0.6490169724627262 from 0.0\n",
      "Epoch 2/15  loss=0.1113  val_loss=0.1030  f1=0.664  time=154.80s\n",
      "model_saved at f1: 0.6642496439207562 from 0.6490169724627262\n",
      "Epoch 3/15  loss=0.1058  val_loss=0.0998  f1=0.676  time=162.17s\n",
      "model_saved at f1: 0.6764218125060969 from 0.6642496439207562\n",
      "Epoch 4/15  loss=0.1024  val_loss=0.0987  f1=0.683  time=151.96s\n",
      "model_saved at f1: 0.6831959416613824 from 0.6764218125060969\n",
      "Epoch 5/15  loss=0.0998  val_loss=0.0989  f1=0.684  time=155.06s\n",
      "model_saved at f1: 0.684330447236508 from 0.6831959416613824\n",
      "Epoch 6/15  loss=0.0973  val_loss=0.0959  f1=0.692  time=155.47s\n",
      "model_saved at f1: 0.691929602029491 from 0.684330447236508\n",
      "Epoch 7/15  loss=0.0954  val_loss=0.0955  f1=0.691  time=163.02s\n",
      "Epoch 8/15  loss=0.0932  val_loss=0.0948  f1=0.693  time=155.07s\n",
      "model_saved at f1: 0.6931155192532089 from 0.691929602029491\n",
      "Epoch 9/15  loss=0.0917  val_loss=0.0959  f1=0.693  time=155.03s\n",
      "model_saved at f1: 0.6933384257933098 from 0.6931155192532089\n",
      "Epoch 10/15  loss=0.0901  val_loss=0.0955  f1=0.695  time=155.54s\n",
      "model_saved at f1: 0.6945321217918062 from 0.6933384257933098\n",
      "Epoch 11/15  loss=0.0885  val_loss=0.0978  f1=0.695  time=155.07s\n",
      "model_saved at f1: 0.6951708341286504 from 0.6945321217918062\n",
      "Epoch 12/15  loss=0.0875  val_loss=0.0966  f1=0.693  time=162.81s\n",
      "Epoch 13/15  loss=0.0859  val_loss=0.0979  f1=0.692  time=155.96s\n",
      "Epoch 14/15  loss=0.0850  val_loss=0.0967  f1=0.695  time=155.90s\n",
      "Epoch 15/15  loss=0.0839  val_loss=0.0977  f1=0.693  time=154.53s\n",
      "{'threshold': 0.29538363218307495, 'f1': 0.6886821078183473}\n",
      "f1 score: 0.7014357868452414\n"
     ]
    }
   ],
   "source": [
    "train_preds, test_preds = training(train_x, train_y, test_x, c, embeddings)\n",
    "search_result = threshold_search(train_y, train_preds)\n",
    "print(search_result)\n",
    "test_pred_targets = test_preds > search_result['threshold']\n",
    "f1 = f1_score(test_df['target'], test_pred_targets)\n",
    "print('f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
